# Bitcoin Sentiment Analysis

## Overview

This project investigates the impact of Bitcoin-related tweet sentiment on Bitcoin (BTC) price movements. Using NLP techniques, including sentiment analysis, we analyze over 1.3 million tweets from December 2022 to predict the direction of Bitcoin's hourly returns. The project leverages minute-level BTC price data to explore potential correlations and insights into market sentiment.

## Table of Contents

- [Overview](#overview)
- [Data](#data)
- [Project Structure](#project-structure)
- [Setup & Installation](#setup--installation)
- [Usage](#usage)
- [Analysis](#analysis)
- [Model Training](#model-training)
- [Results](#results)
- [Contributing](#contributing)
- [License](#license)

## Data

### 1. Bitcoin Price Data
- **Source**: Binance BTCUSDT data
- **Description**: Minute-level and hourly BTC price information from 2022.
- **Key Files**:
  - `Binance_BTCUSDT_1h.csv`: Hourly BTC prices.
  - `Binance_BTCUSDT_2022_minute.csv`: Minute-level BTC prices, used for generating 15- and 30-minute returns.
  
### 2. Bitcoin Tweets Data
- **Source**: [Kaggle - Bitcoin Tweets 2021-2022](https://www.kaggle.com/datasets/hiraddolatzadeh/bitcoin-tweets-2021-2022)
- **Description**: Contains 1.3 million Bitcoin-related tweets from December 2022.
- **Columns**:
  - `datetime`: Timestamp of the tweet
  - `date`: Date of the tweet
  - `username`: Twitter user handle
  - `text`: Content of the tweet
- **Indication**: The file might not be included in the repository since its dimension exceeds the limit. You can download it for free on the link above.

## Project Structure

```
bitcoin_sentiment_analysis/
├── data/                             # Contains raw and processed datasets
│   ├── raw/                          # Raw, unprocessed datasets
│   │   ├── Binance_BTCUSDT_2022_minute.csv
│   │   ├── Binance_BTCUSDT_1h.csv
│   │   └── bitcoin-tweets-2022.csv
│   ├── processed/                    # Preprocessed datasets
│       ├── btc_data_processed.csv    # Cleaned Bitcoin price data
│       ├── tweets_data_december.csv  # Filtered tweets (December 2022)
│       └── merged_data.csv           # Data merged for modeling
│
├── notebooks/                        # Contains Jupyter notebooks for analysis
│   ├── Exploratory_Data_Analysis.ipynb
│   ├── Sentiment_Analysis_Models.ipynb
│   └── Model_Training.ipynb
│
├── src/                              # Contains scripts for various tasks
│   ├── __init__.py                   # Initialization for the src package
│   ├── data/                         # Scripts for data processing
│   │   ├── load_data.py              # Loading datasets
│   │   └── preprocess_data.py        # Preprocessing steps
│   ├── features/                     # Scripts for feature engineering
│   │   └── feature_engineering.py    # Creating and managing features
│   ├── models/                       # Scripts for training and evaluation
│   │   ├── train_model.py            # Model training logic
│   │   ├── evaluate_model.py         # Evaluation logic
│   │   └── hyperparameter_tuning.py  # Grid search and optimization
│   ├── sentiment/                    # Sentiment analysis scripts
│   │   ├── vader_sentiment.py        # VADER sentiment analysis
│   │   ├── bert_sentiment.py         # BERT-based sentiment analysis
│   │   └── cryptobert_sentiment.py   # CryptoBERT sentiment analysis
│   ├── utils/                        # Utility scripts
│   │   └── helpers.py                # General utility functions
│   └── visualization/                # Scripts for plotting
│       └── plot_functions.py         # Functions to visualize data and results
│
├── models/                           # Saved models and serialized files
│   ├── random_forest.pkl             # Trained Random Forest model
│   ├── svm_model.pkl                 # Trained SVM model
│   └── xgboost_model.pkl             # Trained XGBoost model
│
├── reports/                          # Reports, results, and analysis
│   ├── figures/                      # Visualizations and plots
│   ├── final_report.pdf              # Compiled final report in PDF
│   └── draft_latex/                  # LaTeX files for report
│       ├── main.tex                  # Main LaTeX file
│       ├── bibliography.bib          # References file
│       └── figures/                  # Figures used in the LaTeX report
│
├── tests/                            # Test scripts
│   ├── test_data_preprocessing.py    # Tests for preprocessing scripts
│   ├── test_sentiment_analysis.py    # Tests for sentiment models
│   └── test_model_training.py        # Tests for model training logic
│
├── outputs/                          # Outputs generated by the pipeline
│   ├── cleaned_data.csv              # Cleaned data output
│   ├── sentiment_scores.csv          # Sentiment scores
│   └── model_predictions.csv         # Model predictions
│
├── requirements.txt                  # Dependencies for the project
├── README.md                         # Project documentation
├── main.py                           # Main script to run the pipeline
└── .gitignore                        # Git ignore file


```

### Descriptions

- **data/**: Contains all data files, separated into subdirectories:
  - **raw/**: Holds original datasets in their unmodified state, including:
    - `Binance_BTCUSDT_2022_minute.csv`: Minute-level BTC price data for 2022.
    - `bitcoin-tweets-2022.csv`: Bitcoin-related tweets from 2022.
  - **processed/**: Stores cleaned and processed data ready for modeling, including:
    - `btc_data_processed.csv`: Cleaned Bitcoin price data.
    - `tweets_data_december.csv`: Filtered tweets for December 2022.
    - `merged_data.csv`: Merged dataset of sentiment and returns.

- **notebooks/**: Jupyter notebooks for exploratory data analysis, sentiment analysis, and model training:
  - `Exploratory_Data_Analysis.ipynb`: For initial data exploration and visualization.
  - `Sentiment_Analysis_Models.ipynb`: For testing and comparing sentiment analysis techniques.
  - `Model_Training.ipynb`: For model training and evaluation.

- **src/**: Source code for the project's pipeline, divided into specific functionalities:
  - **data/**: Scripts for loading and preprocessing raw data:
    - `load_data.py`: Functions for loading datasets.
    - `preprocess_data.py`: Steps for cleaning and preparing data.
  - **features/**: Scripts for feature generation and extraction:
    - `feature_engineering.py`: Functions to engineer features from datasets.
  - **models/**: Scripts for training, evaluating, and tuning models:
    - `train_model.py`: Logic for training machine learning models.
    - `evaluate_model.py`: Functions for model evaluation.
    - `hyperparameter_tuning.py`: Scripts for grid search and optimization.
  - **sentiment/**: Scripts for sentiment analysis using different models:
    - `vader_sentiment.py`: VADER sentiment analysis implementation.
    - `bert_sentiment.py`: BERT-based sentiment analysis.
    - `cryptobert_sentiment.py`: CryptoBERT sentiment analysis.
  - **utils/**: General utility functions for common tasks:
    - `helpers.py`: Helper functions used across the pipeline.
  - **visualization/**: Scripts for generating plots and figures:
    - `plot_functions.py`: Functions for data visualization.

- **models/**: Directory to store trained machine learning models and serialized files:
  - `random_forest.pkl`: Random Forest model.
  - `svm_model.pkl`: Support Vector Machine model.
  - `xgboost_model.pkl`: XGBoost model.

- **reports/**: Contains project reports and related files:
  - `final_report.pdf`: The compiled LaTeX report for the project.


- **tests/**: Includes unit tests for project scripts:
  - `test_data_preprocessing.py`: Tests for data preprocessing scripts.
  - `test_sentiment_analysis.py`: Tests for sentiment analysis methods.
  - `test_model_training.py`: Tests for model training and evaluation.

- **outputs/**: Stores outputs generated during the pipeline execution:
  - `cleaned_data.csv`: The final cleaned dataset.
  - `sentiment_scores.csv`: Sentiment analysis results.
  - `model_predictions.csv`: Predictions from trained models.

- **requirements.txt**: Specifies all Python dependencies required for running the project.

- **README.md**: This document serves as the project's primary documentation.

- **main.py**: The central script for orchestrating the entire pipeline, including data preprocessing, sentiment analysis, feature engineering, and model training.



## Setup & Installation

1. **Clone the Repository**
   ```bash
   git clone https://github.com/yourusername/bitcoin_sentiment_analysis.git
   cd bitcoin_sentiment_analysis
   ```

2. **Create a Virtual Environment**
   ```bash
   python -m venv .venv
   ```

3. **Activate the Virtual Environment**
   - **Windows:**
     ```bash
     .venv\Scripts\activate
     ```
   - **macOS/Linux:**
     ```bash
     source .venv/bin/activate
     ```

4. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

## Usage

1. **Run the Main Script**
   ```bash
   python main.py
   ```

   This script will:
   - Load and preprocess the data.
   - Perform sentiment analysis.
   - Engineer features.
   - Train the predictive model.
   - Save the outputs.

2. **Explore Notebooks**
   - Navigate to the `notebooks/` directory and open `Exploratory_Data_Analysis.ipynb` to perform EDA and visualize data insights.

## Analysis
- Sentiment Analysis: Uses both BERT "kk08 cryptobert" for crypto-specific sentiment and VADER for general sentiment scoring.
- Feature Engineering: Combines sentiment scores, tweet counts, and Bitcoin price returns over various time intervals.
- Lagged Features: Includes lagged sentiment scores to capture sentiment shifts over time.
  
## Model Training
- Models: Random Forest, XGBoost, and SVM, chosen for their effectiveness in binary classification tasks.
- Hyperparameter Tuning: Applied grid search or random search to optimize model parameters.
- Evaluation Metrics: Models were evaluated based on Accuracy, ROC-AUC, and F1-score.
  
## Results
The project demonstrated that tweet sentiment has a moderate correlation with Bitcoin price movements. Sentiment scores, especially when lagged, were shown to contribute predictive power for determining the return sign of Bitcoin prices in hourly intervals.



## Contributing

Contributions are welcome! Please fork the repository and create a pull request with your changes.

1. **Fork the Repository**
2. **Create a Feature Branch**
   ```bash
   git checkout -b feature/YourFeature
   ```
3. **Commit Your Changes**
   ```bash
   git commit -m "Add YourFeature"
   ```
4. **Push to the Branch**
   ```bash
   git push origin feature/YourFeature
   ```
5. **Open a Pull Request**

## License

This project is licensed under the [MIT License](LICENSE).

## Acknowledgements

- [Kaggle Datasets](https://www.kaggle.com/datasets/hiraddolatzadeh/bitcoin-tweets-2021-2022)
- [VADER Sentiment Analysis](https://github.com/cjhutto/vaderSentiment)
- [Gensim for Topic Modeling](https://radimrehurek.com/gensim/)

